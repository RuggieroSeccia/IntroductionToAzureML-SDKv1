{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor a Model\n",
    "\n",
    "When you've deployed a model into production as a service, you'll want to monitor it to track usage and explore the requests it processes. You can use Azure Application Insights to monitor activity for a model service endpoint.\n",
    "\n",
    "This notebooks is based on the DP-100 tutorial from [here](https://github.com/MicrosoftLearning/mslearn-dp100/blob/main/16%20-%20Monitor%20a%20Model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change working directory\n",
    "import os\n",
    "\n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\"\n",
    "import git\n",
    "\n",
    "repo = git.Repo(os.getcwd(), search_parent_directories=True)\n",
    "os.chdir(repo.working_tree_dir)\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# download the model files\n",
    "import os\n",
    "from pathlib import Path\n",
    "from azureml.core import Model, Workspace\n",
    "workspace = Workspace.from_config()\n",
    "model_name = 'RuggieroS_Model-EF-MLOPS'\n",
    "model_version = '4'\n",
    "output_dir = Path('data/model_files')\n",
    "model = Model(workspace=workspace,\n",
    "              name=model_name,\n",
    "              version=model_version)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "model.download(output_dir, exist_ok=True)\n",
    "\n",
    "print(f'Model files downloaded and saved at location {output_dir}')\n",
    "model_files_path = os.path.join(output_dir, 'model_pipeline')\n",
    "list_of_files = os.listdir(model_files_path)\n",
    "if list_of_files:\n",
    "    print(\"The following files are downloaded:\")\n",
    "    for file in list_of_files:\n",
    "        print(file)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Either the files are not downloaded or the files are not saved at the location {model_files_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './bike_sharing_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_bike_sharing.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need an entry script that the service will use to score new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $script_path\n",
    "import mlflow\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'model_pipeline' )\n",
    "    mlflow_pipeline = mlflow.pyfunc.load_model(model_path)\n",
    "    model = mlflow_pipeline._model_impl.python_model.model\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = json.loads(raw_data)['data']\n",
    "    df_data = pd.DataFrame.from_dict(json.loads(data))\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(df_data)\n",
    "    \n",
    "    # print the data and predictions (so they'll be logged!)\n",
    "    log_text = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
    "    print(log_text)\n",
    "    \n",
    "\n",
    "    return json.dumps({idx: p for idx, p in enumerate(predictions)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the service (in this case, as an Azure Container Instance (ACI).\n",
    "\n",
    "> **Note**: This can take a few minutes - wait until the state is shown as **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=Environment.from_conda_specification(\n",
    "                                       \".venv\", \"./environment.yml\"\n",
    "                                   ))\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"bikes-service-app-insights\"\n",
    "aci_service = Model.deploy(workspace, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "aci_service.wait_for_deployment(show_output = True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Application Insights\n",
    "\n",
    "Next, you need to enable Application Insights for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Enable AppInsights\n",
    "aci_service.update(enable_app_insights=True)\n",
    "print('AppInsights enabled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the web service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application.\n",
    "\n",
    "First, determine the URL to which these applications must submit their requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "endpoint = aci_service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es).\n",
    "\n",
    "> **Tip**: If an error occurs because the service endpoint isn't ready. Wait a few seconds and try again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# we create some data to test the API.\n",
    "# Since the preprocessing steps performed in the DataTransformer are not saved in the model, we need to apply the same operations to the data below\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(r'data\\BikeSharingPredictionsHours.csv', sep=';')\n",
    "df.drop(['dteday'], axis=1, inplace=True)\n",
    "df.drop(['holiday', 'registered', 'casual', 'cnt'], axis=1, inplace=True)\n",
    "coef = 2 * np.pi / 23.0\n",
    "df['hour_sin'] = np.sin(coef * df['hr'])\n",
    "df['hour_cos'] = np.cos(coef * df['hr'])\n",
    "df.rename(columns={'yr': 'year', 'mnth': 'month', 'weekday': 'week_day',\n",
    "                   'workingday': 'working_day', 'weathersit': 'weather_situation', 'atemp': 'temp_feel',\n",
    "                   'hum': 'humidity', 'windspeed': 'wind_speed'}, inplace=True)\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": df.head().to_json()})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "# Get the predictions\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predictions.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can view the data logged for the service endpoint:\n",
    "\n",
    "1. In the [Azure portal](https://portal.azure.com), open your Machine Learning workspace.\n",
    "2. On the **Overview** page, click the link for the associated **Application Insights** resource.\n",
    "3. On the Application Insights blade, click **Logs**. \n",
    "\n",
    "    > **Note**: If this is the first time you've opened log analytics, you may need to click **Get Started** to open the query editor. If a tip explaining how to write a query is displayed, close it.\n",
    "\n",
    "4. Paste the following query into the query editor and click **Run**\n",
    "    ```\n",
    "    traces\n",
    "    |where  message == \"STDOUT\"\n",
    "      and customDimensions.[\"Service Name\"] == \"bikes-service-app-insights\"\n",
    "    |project timestamp, customDimensions.Content\n",
    "    ```\n",
    "5. View the results. At first there may be none, because an ACI web service can take as long as five minutes to send the telemetry to Application Insights. Wait a few minutes and re-run the query until you see the logged data and predictions.\n",
    "6. When you've reviewed the logged data, close the Application Insights query page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the service\n",
    "\n",
    "When you no longer need your service, you should delete it.\n",
    "\n",
    "> **Note**: If the service is in use, you may not be able to delete it immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    aci_service.delete()\n",
    "    print('Service deleted.')\n",
    "except Exception as ex:\n",
    "    print(ex.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about using Application Insights to monitor a deployed service, see the [Azure Machine Learning documentation](https://docs.microsoft.com/azure/machine-learning/how-to-enable-app-insights)."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
